





import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import pickle
import joblib

from darts import TimeSeries
from darts.models import NBEATSModel
from darts.dataprocessing.transformers import Scaler
from darts.metrics import rmse, mae


#Prices data set
file_id_1 = "1iutsbqnuMuUgmd_FuKt_1x5s0whbdV2U"
download_url_1 = f"https://drive.google.com/uc?id={file_id_1}"
item_price_1 = pd.read_csv(download_url_1)

file_id_2 = "17PbW-iHxFaYJor4tEzYopwBkMCi-8VRm"
download_url_2 = f"https://drive.google.com/uc?id={file_id_2}"
item_price_2 = pd.read_csv(download_url_2)

file_id_3 = "1Lz-QjwhM0YGTpTddQX2nyTEUBORrnsba"
download_url_3 = f"https://drive.google.com/uc?id={file_id_3}"
item_price_3 = pd.read_csv(download_url_3)

file_id_4 = "1MQBKY7sBZO1pe2TgSHa2pk1wxCOTkpIi"
download_url_4 = f"https://drive.google.com/uc?id={file_id_4}"
item_price_4 = pd.read_csv(download_url_4)

file_id_5 = "1m3NIwllKxkpZ3uwVHczXZy8tIvFAkxib"
download_url_5 = f"https://drive.google.com/uc?id={file_id_5}"
item_price_5 = pd.read_csv(download_url_5)

item_price = pd.concat([item_price_1, item_price_2, item_price_3, item_price_4, item_price_5], ignore_index=True)


#Events file
file_1 = "1X2XBvxf-DlRe1nym1wdL_Ct7GoCEtyLj"
url_1 = f"https://drive.google.com/uc?id={file_1}"
item_sales_1 = pd.read_csv(url_1)

file_2 = "1PIJsGPJCJm7gEOxChFNXjvb0E9Z4yb3F"
url_2 = f"https://drive.google.com/uc?id={file_2}"
item_sales_2 = pd.read_csv(url_2)

file_3 = "192CNuSqVj87xz5jVlK0K3rs4B4rTHkRQ"
url_3 = f"https://drive.google.com/uc?id={file_3}"
item_sales_3 = pd.read_csv(url_3)

file_4 = "1SFZoai5yzKSQn8s8EdxA16-FRgXGdLgy"
url_4 = f"https://drive.google.com/uc?id={file_4}"
item_sales_4 = pd.read_csv(url_4)

item_sales = pd.concat([item_sales_1, item_sales_2, item_sales_3, item_sales_4], ignore_index=True)


#Events file
file_id = "1gLVp1-FeQ1PbpfvnyVNS99FVwwr5ntj5"
download_url = f"https://drive.google.com/uc?id={file_id}"

events = pd.read_csv(download_url)








item_price


print(item_price.shape)
print(item_price.columns)


item_price.info(verbose=True)


item_price.describe().T


item_price.describe(include=['object']).T


item_price.isnull().sum()


raw_nan = (item_price['yearweek'].isnull().sum() / len(item_price))
percent_nan = "{:.2%}".format(raw_nan)
print('The percentage of null data in column yearweek is', percent_nan)





mean_prices = pd.DataFrame(item_price.groupby(['item', 'store_code'])['sell_price'].mean().reset_index())


mean_prices





item_sales


print(item_sales.shape)
print(item_sales.columns)


item_sales.info(verbose=False)


item_sales.select_dtypes(include=['object']).isnull().sum()


filtered_columns = item_sales.select_dtypes(include=['number']).isnull().sum() >= 1

# Verificar se alguma coluna está com o valor nulo
if filtered_columns.any():
    print("At least one column has null values.")
else:
    print("No column has null values.")


item_sales.describe().T


item_sales.describe(include=['object']).T





events


print(events.shape)
print(events.columns)


events.select_dtypes(include=['number', 'object']).isnull().sum()


events.describe(include=['object']).T


#changing the name of column d to day so we can merge the file later
events.rename(columns={'d':'day'}, inplace=True)








sales_melted = item_sales.melt(id_vars=['id', 'item', 'category', 'department', 'store', 'store_code', 'region'], var_name='day', value_name='units_sold')


sales_melted.head(10)


sales_prices = sales_melted.merge(mean_prices, how='left', on=['item', 'store_code'])


#creating the final dataframe
df = sales_prices.merge(events, how='left', on='day')





df.dtypes





def memory_usage_mb(df):
    return df.memory_usage(deep=True).sum() / (1024 * 1024)

# Memória original
memory_before = memory_usage_mb(df)
print(f"Memória antes: {memory_before:.2f} MB")


#object column
object_columns = df.select_dtypes(include='object').columns.tolist()
df[object_columns] = df[object_columns].astype('category')


#date time
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')


#numerical columns
df = df.astype(
    {
    'units_sold':'int16',
    'sell_price':'float16',
    'weekday_int':'int8'
    }
)


# events encoding, if it is an event 1, else 0.
df['event'] = np.where(df['event'].isna(), 0, 1).astype('int8')


memory_after = memory_usage_mb(df)

reduction_percentage = 100 * (memory_before - memory_after) / memory_before

print(f"Memory after: {memory_after:.2f} MB")
print(f"Memory reduction: {reduction_percentage:.2f}%")





df_nbeats = df.groupby(['date','event','weekday_int'], as_index=True).agg({'units_sold': 'sum'})


df_nbeats


series = TimeSeries.from_dataframe(df_nbeats, 'date', 'units_sold').astype(np.float32)

series_covariates = TimeSeries.from_dataframe(df_nbeats, time_col='date',
                                              value_cols=['weekday_int', 'event']).astype(np.float32)
